---
---

%special fields include abbr, award, pdf, html, abstract, slides, video, selected

@inproceedings{cao2025visual,
  abbr = {COLM},
  title={What is the visual cognition gap between humans and multimodal llms?},
  author={Cao, Xu and Shen, Yifan and Lai, Bolin and Ye, Wenqian and Ma, Yunsheng and Heintz, Joerg and Chen, Jintai and Huang, Meihuan and Cao, Jianguo and Rehg, James M},
  booktitle={COLM},
  year={2025}
}

@inproceedings{fang2025pgformer,
  abbr = {ICCV},
  title={Proxy-Bridged Game Transformer for Multi-Person Highly Interactive Extreme Motion Prediction},
  author={Fang, Yanwen and Wenqi Jia and Cao, Xu and Jiang, Peng-Tao and Li, Guodong and Chen, Jintai },
  booktitle={ICCV},
  year={2025}
}

@inproceedings{cui2025board,
  abbr = {IROS},
  title={On-board vision-language models for personalized autonomous vehicle motion control: System design and real-world validation},
  author={Cui, Can and Yang, Zichong and Zhou, Yupeng and Peng, Juntong and Park, Sung-Yeon and Zhang, Cong and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Feng, Yiheng and others},
  booktitle={IROS},
  year={2025}
}

@inproceedings{cao2025socialgesture,
  abbr = {CVPR},
  title={SocialGesture: Delving into Multi-person Gesture Understanding},
  author={Cao, Xu and Virupaksha, Pranav and Jia, Wenqi and Lai, Bolin and Ryan, Fiona and Lee, Sangmin and Rehg, James M},
  booktitle={CVPR},
  year={2025},
  pdf = {https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_SocialGesture_Delving_into_Multi-person_Gesture_Understanding_CVPR_2025_paper.pdf},
}

@article{liu2025survey,
  abbr = {Inform Fusion},
  title={From Screens to Scenes: A Survey of Embodied AI in Healthcare},
  author={Liu, Yihao and Cao, Xu and Chen, Tingting and Jiang, Yankai and You, Junjie and Wu, Minghua and Wang, Xiaosong and Feng, Mengling and Jin, Yaochu and Chen, Jintai},
  journal={Information Fusion},
  year={2025},
  html = {https://www.sciencedirect.com/science/article/abs/pii/S156625352500106X},
  pdf = {https://arxiv.org/pdf/2501.07468},
}

@inproceedings{cao2024mpoxvlm,
  abbr = {ML4H},
  award = {Proceedings},
  title={MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection},
  author={Cao, Xu and Ye, Wenqian and Moise, Kenny and Coffee, Megan},
  booktitle={ML4H},
  year={2024}
}

@inproceedings{fallahpour2024ehrmamba,
  abbr = {ML4H},
  award = {Proceedings},
  title={EHRMamba: Towards Generalizable and Scalable Foundation Models for Electronic Health Records},
  author={Fallahpour, Adibvafa and Alinoori, Mahshid and Ye, Wenqian and Cao, Xu and Afkanpour, Arash and Krishnan, Amrit},
  booktitle={ML4H},
  year={2024}
}

@inproceedings{ma2024learning,
  abbr = {EMNLP},
  award = {Findings},
  title={Learning Autonomous Driving Tasks via Human Feedbacks with Large Language Models},
  author={Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Cui, Can and Mei, Kai and Wang, Ziran},
  booktitle={EMNLP},
  pages={4985--4995},
  year={2024},
  pdf = {https://aclanthology.org/2024.findings-emnlp.287.pdf},
}

@article{lee2024towards,
  abbr = {Preprint},
  title={Towards social AI: A survey on understanding social interactions},
  author={Lee, Sangmin and Li, Minzhi and Lai, Bolin and Jia, Wenqi and Ryan, Fiona and Cao, Xu and Kara, Ozgur and Boote, Bikram and Shi, Weiyan and Yang, Diyi and others},
  journal={arXiv preprint arXiv:2409.15316},
  year={2024},
  pdf = {https://arxiv.org/pdf/2409.15316},
}

@inproceedings{cao2024maplm,
  abbr = {CVPR},
  title={MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding},
  author={Cao, Xu and Zhou, Tong and Ma, Yunsheng and Ye, Wenqian and Cui, Can and Tang, Kun and Cao, Zhipeng and Liang, Kaizhao and Wang, Ziran and Rehg, James M and others},
  booktitle={CVPR},
  pages={21819--21830},
  year={2024}
}

@inproceedings{ma2024lampilot,
  abbr = {CVPR},
  title={Lampilot: An open benchmark dataset for autonomous driving with language model programs},
  author={Ma, Yunsheng and Cui, Can and Cao, Xu and Ye, Wenqian and Liu, Peiran and Lu, Juanwu and Abdelraouf, Amr and Gupta, Rohit and Han, Kyungtae and Bera, Aniket and others},
  booktitle={CVPR},
  pages={15141--15151},
  year={2024}
}

@inproceedings{cui2024survey,
  abbr = {WACVW},
  title={A survey on multimodal large language models for autonomous driving},
  author={Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others},
  booktitle={WACV Workshop},
  pages={958--979},
  year={2024}
}

@inproceedings{cui2024drive,
  abbr = {WACVW},
  title={Drive as you speak: Enabling human-like interaction with large language models in autonomous vehicles},
  author={Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Wang, Ziran},
  booktitle={WACV Workshop},
  pages={902--909},
  year={2024}
}

@inproceedings{ma2024macp,
  abbr = {WACV},
  title={MACP: Efficient model adaptation for cooperative perception},
  author={Ma, Yunsheng and Lu, Juanwu and Cui, Can and Zhao, Sicheng and Cao, Xu and Ye, Wenqian and Wang, Ziran},
  booktitle={WACV},
  pages={3373--3382},
  year={2024}
}

@inproceedings{cao2023vitasd,
  abbr = {ICASSP},
  title={Vitasd: Robust vision transformer baselines for autism spectrum disorder facial diagnosis},
  author={Cao, Xu and Ye, Wenqian and Sizikova, Elena and Bai, Xue and Coffee, Megan and Zeng, Hongwu and Cao, Jianguo},
  booktitle={ICASSP},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{cao2023commentary,
  abbr = {JCPP},
  title={Commentary: Machine learning for autism spectrum disorder diagnosis--challenges and opportunities},
  author={Cao, Xu and Cao, Jianguo},
  journal={Journal of Child Psychology and Psychiatry},
  volume={64},
  number={6},
  pages={966--967},
  year={2023},
  publisher={Wiley Online Library}
}

@article{zheng2023high,
  abbr = {AI Magazine},
  title={High-definition map automatic annotation system based on active learning},
  author={Zheng, Chao and Cao, Xu and Tang, Kun and Cao, Zhipeng and Sizikova, Elena and Zhou, Tong and Li, Erlong and Liu, Ao and Zou, Shengtao and Yan, Xinrui and others},
  journal={AI Magazine},
  volume={44},
  number={4},
  pages={418--430},
  year={2023},
  publisher={Wiley Online Library}
}


@inproceedings{ye2023mitigating,
  abbr = {UAI},
  title={Mitigating transformer overconfidence via Lipschitz regularization},
  author={Ye, Wenqian and Ma, Yunsheng and Cao, Xu and Tang, Kun},
  booktitle={UAI},
  pages={2422--2432},
  year={2023},
  organization={PMLR},
  html = {https://proceedings.mlr.press/v216/ye23a.html},
  selected = {true}
}

@inproceedings{tang2023thma,
  abbr = {AAAI},
  award = {Oral in IAAI},
  title={THMA: Tencent hd map ai system for creating hd map annotations},
  author={Tang, Kun and Cao, Xu and Cao, Zhipeng and Zhou, Tong and Li, Erlong and Liu, Ao and Zou, Shengtao and Liu, Chang and Mei, Shuqi and Sizikova, Elena and others},
  booktitle={AAAI},
  volume={37},
  number={13},
  pages={15585--15593},
  year={2023},
  html = {https://ojs.aaai.org/index.php/AAAI/article/view/26848}
}

@inproceedings{cao2022aggpose,
  abbr = {IJCAI},
  award = {Oral},
  title={Aggpose: Deep aggregation vision transformer for infant pose estimation},
  booktitle = {IJCAI},
  author={Cao, Xu and Li, Xiaoye and Ma, Liya and Huang, Yi and Feng, Xuan and Chen, Zening and Zeng, Hongwu and Cao, Jianguo},
  year={2022},
  pdf = {https://www.ijcai.org/proceedings/2022/0700.pdf},
  selected = {true}
}

